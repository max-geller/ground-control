# ğŸ¦ Ground Control â€” Architecture

> How data flows from OpenClaw session logs to your terminal.

This document describes how the Ground Control ecosystem fits together: how cost and usage data is collected, stored, and surfaced to both humans and agents.

---

## Overview

Ground Control follows a simple three-stage pipeline: **ingest â†’ store â†’ act**.

All cost and usage data originates locally. OpenClaw logs every model response â€” from every provider â€” to session JSONL files on the VPS. Each assistant message includes full token counts. Ground Control ingests these logs, computes estimated costs from a static pricing table, and writes per-request events to a local SQLite database. No external API polling. No relay infrastructure. No network dependency.

```
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                      HOST / VPS                          â”‚
  â”‚                                                          â”‚
  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
  â”‚  â”‚                OPENCLAW GATEWAY                    â”‚  â”‚
  â”‚  â”‚                                                    â”‚  â”‚
  â”‚  â”‚  Providers: Anthropic, OpenAI, Google, etc         â”‚  â”‚
  â”‚  â”‚                                                    â”‚  â”‚
  â”‚  â”‚  Every model response â†’ session JSONL with usage   â”‚  â”‚
  â”‚  â”‚  ~/.openclaw/agents/*/sessions/*.jsonl             â”‚  â”‚
  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
  â”‚                         â”‚                                â”‚
  â”‚                    JSONL files                           â”‚
  â”‚                    (append-only)                         â”‚
  â”‚                         â”‚                                â”‚
  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
  â”‚  â”‚             INGESTION SERVICE                      â”‚  â”‚
  â”‚  â”‚           (cron or file-watcher)                   â”‚  â”‚
  â”‚  â”‚                                                    â”‚  â”‚
  â”‚  â”‚  1. Tail new JSONL entries since last offset       â”‚  â”‚
  â”‚  â”‚  2. Extract usage events (input, output, cache)    â”‚  â”‚
  â”‚  â”‚  3. Map agent â†’ provider â†’ model                   â”‚  â”‚
  â”‚  â”‚  4. Multiply tokens Ã— static pricing table         â”‚  â”‚
  â”‚  â”‚  5. Write per-request events to SQLite             â”‚  â”‚
  â”‚  â”‚  6. Check budget alerts                            â”‚  â”‚
  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
  â”‚                         â”‚                                â”‚
  â”‚                         â–¼                                â”‚
  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
  â”‚  â”‚             SQLite Database                        â”‚  â”‚
  â”‚  â”‚          ~/.openclaw/cost-tracking.db              â”‚  â”‚
  â”‚  â”‚                                                    â”‚  â”‚
  â”‚  â”‚  usage_events | model_pricing | agents | alerts    â”‚  â”‚
  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
  â”‚           â”‚                   â”‚                          â”‚
  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
  â”‚  â”‚   TELEMETRY     â”‚  â”‚    RELAY         â”‚               â”‚
  â”‚  â”‚   (TUI/CLI)     â”‚  â”‚    (TUI/CLI)     â”‚               â”‚
  â”‚  â”‚                 â”‚  â”‚                  â”‚               â”‚
  â”‚  â”‚  Cost views,    â”‚  â”‚  Task mgmt,      â”‚               â”‚
  â”‚  â”‚  budget alerts, â”‚  â”‚  Kanban,         â”‚               â”‚
  â”‚  â”‚  optimization   â”‚  â”‚  assignments     â”‚               â”‚
  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
  â”‚           â”‚                  â”‚                           â”‚
  â”‚           â–¼                  â–¼                           â”‚
  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
  â”‚  â”‚              OPENCLAW AGENTS                       â”‚  â”‚
  â”‚  â”‚                                                    â”‚  â”‚
  â”‚  â”‚  â€¢ Read costs via CLI (sub-millisecond)            â”‚  â”‚
  â”‚  â”‚  â€¢ Create/update tasks via CLI                     â”‚  â”‚
  â”‚  â”‚  â€¢ Suggest optimizations                           â”‚  â”‚
  â”‚  â”‚  â€¢ Await human approval                            â”‚  â”‚
  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
  â”‚                                                          â”‚
  â”‚  All reads are local. Sub-millisecond. No network deps.  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


```

---

## Component Details

### Data Source: OpenClaw Session JSONL

**What it is:** The raw usage data that OpenClaw already produces.

**Where it lives:**

```
~/.openclaw/agents/{agent_name}/sessions/*.jsonl
```

Each agent has its own session directory. Agent attribution is automatic â€” the directory name _is_ the agent.

**What a usage event looks like:**

```json
{
  "type": "message",
  "message": {
    "role": "assistant",
    "provider": "anthropic",
    "model": "claude-opus-4-6",
    "usage": {
      "input": 45230,
      "output": 1847,
      "cacheRead": 108928,
      "cacheWrite": 4200,
      "cost": { "total": 0.85 }
    },
    "timestamp": 1769753935279
  }
}
```

**Provider field values:** `anthropic`, `openai`, `openai-codex`, `google`, etc.

**Token fields by provider:**

| Field        | Anthropic             | OpenAI                     | Google   |
| ------------ | --------------------- | -------------------------- | -------- |
| `input`      | âœ“ (uncached)          | âœ“ (total, includes cached) | âœ“        |
| `output`     | âœ“                     | âœ“                          | âœ“        |
| `cacheRead`  | âœ“                     | âœ“                          | âœ“        |
| `cacheWrite` | âœ“                     | â€” (free)                   | â€” (free) |
| `cost.total` | âœ“ (OpenClaw estimate) | âœ“                          | âœ“        |

**Why this replaces the relay:** The data already exists locally. OpenClaw logs every model response with full token counts from all three providers. There's no need to poll external admin APIs when the same information originates on the VPS. This eliminates the Cloudflare Worker, D1 database, sync mechanism, admin API keys, and ~864 external API calls per day.

---

### Ingestion Service

**What it is:** A lightweight script (Python or Node) that runs on a cron (every 1-5 minutes) or as a file watcher.

**What it does:** Tails OpenClaw's session JSONL files, extracts usage events from assistant messages, computes estimated costs using the static pricing table, and writes per-request events to SQLite.

**How it works:**

1. Read `ingestion_state` table to get last-processed file offset per session file
2. Scan `~/.openclaw/agents/*/sessions/*.jsonl` for new data past stored offsets
3. For each new JSONL line with `type: "message"`, `role: "assistant"`, and usage data:
   - Extract provider, model, token counts, timestamp
   - Derive `agent_id` from the directory path
   - Look up current pricing from `model_pricing` table
   - Compute estimated cost: `(input Ã— input_rate + output Ã— output_rate + cacheRead Ã— cache_read_rate + cacheWrite Ã— cache_write_rate) / 1,000,000`
   - Insert into `usage_events`
4. Update `ingestion_state` with new file offsets
5. Check budget alerts and fire if thresholds are exceeded

**Key design decisions:**

- Idempotent re-runs via offset tracking. The script picks up where it left off.
- Per-request granularity (not pre-aggregated buckets). You get exact attribution: which session, which model call, which agent.
- Aggregation happens at query time, not at ingestion time.
- If OpenClaw rotates or archives session files, old entries in `ingestion_state` are simply ignored.

---

### Cost Estimation: The Static Pricing Table

**Target accuracy: ~90%.** Good enough for agents to understand their cost profile, identify expensive patterns, and self-optimize. Not for invoice reconciliation.

Published model pricing changes 2-3 times per year, announced in advance. Between changes, the pricing table is exact for standard usage. The only sources of drift are:

| Drift Source                                       | Impact                    | Notes                                   |
| -------------------------------------------------- | ------------------------- | --------------------------------------- |
| Context window tiers (Anthropic 0-200k vs 200k-1M) | ~10-20% on affected calls | Only Anthropic, only for large contexts |
| Batch discounts                                    | ~50% lower                | Agents don't typically batch            |
| Cache read discount variance (OpenAI 50-90%)       | Â±20% on cached reads      | Use midpoint estimate                   |

For the intended use case â€” agents asking "should I use Opus or Sonnet for this?" or "am I burning too much on cache writes?" â€” a Â±5-10% cost estimate is more than adequate. The decisions don't change at that margin.

**Optional reconciliation:** Provider billing APIs (Anthropic's `/v1/organizations/cost_report`, OpenAI's `/v1/organization/costs`) remain available for periodic comparison. This could be a weekly script, not a core pipeline dependency.

---

### openclaw-telemetry

**What it is:** A Go binary that runs on your host. Provides both a TUI (for humans) and a CLI (for agents).

**What it does:** Reads from the local SQLite database populated by the ingestion service. Provides cost monitoring, budget tracking, alerting, and optimization analysis.

**Dual interface pattern:**

```
Human (TUI):                          Agent (CLI):

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              $ telemetry cost --today
â”‚  DAILY SPEND BY      â”‚              {"today": 34.19, "budget": 50.00,
â”‚  PROVIDER            â”‚               "remaining": 15.81}
â”‚  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ $34.19     â”‚
â”‚                      â”‚              $ telemetry alert --check
â”‚  BUDGET: $50/day     â”‚              {"alerts": [{"type": "daily_spend",
â”‚  REMAINING: $15.81   â”‚               "threshold": 25.00,
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               "current": 34.19, "status": "triggered"}]}
```

The TUI renders rich, interactive views with charts, tables, and navigation. The CLI returns structured JSON that an agent can parse in minimal tokens.

**SQLite schema (simplified):**

```sql
CREATE TABLE usage_events (
    id                  INTEGER PRIMARY KEY AUTOINCREMENT,
    timestamp           TEXT NOT NULL,       -- ISO 8601 from JSONL event
    agent_id            TEXT NOT NULL,       -- from session directory name
    provider            TEXT NOT NULL,       -- 'anthropic' | 'openai' | 'google'
    model               TEXT NOT NULL,
    input_tokens        INTEGER DEFAULT 0,
    output_tokens       INTEGER DEFAULT 0,
    cache_read_tokens   INTEGER DEFAULT 0,
    cache_write_tokens  INTEGER DEFAULT 0,   -- Anthropic only
    total_tokens        INTEGER DEFAULT 0,
    estimated_cost_usd  REAL,
    session_file        TEXT,
    session_id          TEXT
);

CREATE TABLE agents (
    id                  TEXT PRIMARY KEY,    -- 'dex', 'cassandra', 'max', 'borkus'
    display_name        TEXT NOT NULL,
    monthly_budget_usd  REAL,               -- null = no limit
    daily_alert_usd     REAL,
    is_active           INTEGER DEFAULT 1
);

CREATE TABLE model_pricing (
    provider        TEXT NOT NULL,
    model           TEXT NOT NULL,
    token_type      TEXT NOT NULL,           -- 'input' | 'output' | 'cache_read' | 'cache_write'
    cost_per_mtok   REAL NOT NULL,           -- USD per 1M tokens
    effective_date  TEXT NOT NULL,
    PRIMARY KEY (provider, model, token_type, effective_date)
);

CREATE TABLE alerts (
    id          INTEGER PRIMARY KEY AUTOINCREMENT,
    metric      TEXT NOT NULL,
    threshold   REAL NOT NULL,
    enabled     INTEGER DEFAULT 1,
    created_at  TEXT NOT NULL
);

CREATE TABLE optimization_suggestions (
    id                    INTEGER PRIMARY KEY AUTOINCREMENT,
    agent_id              TEXT NOT NULL,
    suggestion            TEXT NOT NULL,
    reasoning             TEXT,
    estimated_savings_usd REAL,
    status                TEXT DEFAULT 'pending',  -- 'pending', 'approved', 'denied'
    created_at            TEXT NOT NULL,
    reviewed_at           TEXT
);

CREATE TABLE ingestion_state (
    file_path     TEXT PRIMARY KEY,
    last_offset   INTEGER NOT NULL DEFAULT 0,
    last_line_ts  TEXT,
    updated_at    TEXT DEFAULT (datetime('now'))
);
```

**The cost feedback loop:**

This is the core value proposition of Telemetry. It's not just a dashboard â€” it's a feedback loop:

1. **OpenClaw** logs every model response to session JSONL files
2. **Ingestion service** tails the logs, computes costs, writes to SQLite
3. **Agents** query their own cost data via CLI
4. **Agents** analyze patterns (cache hit rates, model costs, session efficiency)
5. **Agents** create optimization suggestions (stored in `optimization_suggestions` table)
6. **Humans** review suggestions in the TUI and approve/deny them
7. **Agents** read approved suggestions and adjust their behavior
8. Repeat

This loop means your agents are actively participating in their own cost optimization, but humans retain approval authority over changes. The agent can say "I think switching this task to Sonnet would save $2/day" â€” and you decide whether to let it.

---

### openclaw-dispatch

**What it is:** A Go binary that provides task management for both agents and humans.

**What it does:** Dispatch is a shared task board where humans assign work, agents pick up tasks, update status, and report results. Humans see the Kanban/table TUI. Agents interact via CLI.

**Dual interface pattern:**

```
Human (TUI):                          Agent (CLI):

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              $ dispatch task create \
â”‚  Todo (5)  â”‚ Active  â”‚                --title "Analyze cache ratios" \
â”‚            â”‚  (2)    â”‚                --priority 2 \
â”‚  #67 Max   â”‚ #104    â”‚                --assignee dex
â”‚  Restart.. â”‚ Review  â”‚
â”‚            â”‚ WF45A.. â”‚              $ dispatch task update \
â”‚  #9 Cass   â”‚         â”‚                --id 104 \
â”‚  Cost Op.. â”‚         â”‚                --status done \
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                --notes "Cache ratio improved to 22%"
```

**SQLite schema (simplified):**

```sql
CREATE TABLE tasks (
    id          INTEGER PRIMARY KEY AUTOINCREMENT,
    title       TEXT NOT NULL,
    description TEXT,
    project     TEXT,
    priority    INTEGER DEFAULT 3,
    status      TEXT DEFAULT 'todo',
    assignee    TEXT,
    due_date    TEXT,
    created_at  TEXT NOT NULL,
    updated_at  TEXT NOT NULL
);

CREATE TABLE task_comments (
    id          INTEGER PRIMARY KEY AUTOINCREMENT,
    task_id     INTEGER NOT NULL REFERENCES tasks(id),
    author      TEXT NOT NULL,
    content     TEXT NOT NULL,
    created_at  TEXT NOT NULL
);
```

**Key design decisions:**

- Tasks have assignees that can be either humans or agent names. The system doesn't distinguish â€” a task assigned to "dex" is the same data structure as one assigned to "max."
- Agents create and update tasks via CLI with structured flags. No natural language parsing, no prompt overhead.
- The TUI provides filtering by assignee, project, priority, and status. The CLI supports the same filters as flags.

---

## Token Efficiency: Why This Matters

The entire architecture is designed around one principle: **minimize the tokens agents spend on operational overhead.**

| Operation           | Google Sheets Approach | Ground Control CLI |
| ------------------- | ---------------------- | ------------------ |
| Read today's cost   | ~2,000-4,000 tokens    | ~50-150 tokens     |
| Create a task       | ~1,500-3,000 tokens    | ~80-200 tokens     |
| Check budget status | ~2,000-3,500 tokens    | ~40-100 tokens     |
| List active tasks   | ~2,500-4,000 tokens    | ~100-400 tokens    |

Over hundreds of agent interactions per day, this adds up to real dollar savings. The architecture pays for itself.

---

## Data Flow Summary

```
1. LOG        OpenClaw logs every model response to session JSONL
                         â”‚
2. INGEST     Ingestion service tails JSONL, computes costs
                         â”‚
3. STORE      Per-request events written to local SQLite
                         â”‚
4. SURFACE    TUI (humans) and CLI (agents) read from SQLite
                         â”‚
5. ACT        Agents analyze, suggest optimizations
                         â”‚
6. APPROVE    Humans review and approve/deny in TUI
                         â”‚
7. ADAPT      Agents adjust behavior based on approvals
                         â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€ REPEAT â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Consumer Access Patterns

| Consumer                   | Data Source     | Access Method        | Latency |
| -------------------------- | --------------- | -------------------- | ------- |
| **Telemetry TUI**          | Local SQLite    | File read            | <1ms    |
| **Agents (self-throttle)** | Local SQLite    | CLI â†’ file read      | <1ms    |
| **Ingestion service**      | JSONL â†’ SQLite  | Cron or file watcher | 1-5 min |
| **Dashboard (future)**     | SQLite via API  | HTTP from VPS        | ~50ms   |
| **Ad-hoc queries**         | SQLite directly | `sqlite3` CLI        | Instant |

---

## Deployment Model

The typical Ground Control deployment runs entirely on a single host:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Your VPS / Host                â”‚
â”‚                                          â”‚
â”‚  OpenClaw Gateway (agents + providers)   â”‚
â”‚        â”‚                                 â”‚
â”‚        â–¼                                 â”‚
â”‚  Session JSONL files                     â”‚
â”‚        â”‚                                 â”‚
â”‚        â–¼                                 â”‚
â”‚  Ingestion Service (cron)                â”‚
â”‚        â”‚                                 â”‚
â”‚        â–¼                                 â”‚
â”‚  SQLite database                         â”‚
â”‚        â”‚                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”                            â”‚
â”‚   â–¼         â–¼                            â”‚
â”‚  Telemetry  Dispatch                     â”‚
â”‚  (TUI/CLI)  (TUI/CLI)                   â”‚
â”‚                                          â”‚
â”‚  Zero external dependencies.             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Minimum requirements for the host:**

- Linux (any distro), macOS, or Windows
- ~50MB disk for binaries
- ~10MB RAM per tool (Go is efficient)
- SQLite 3 (usually pre-installed)
- Access to OpenClaw session directories

This runs comfortably on a $5/month KVM VPS. It was designed to.

---

## Future Architecture Considerations

**Web dashboard:** A SvelteKit app reading from a lightweight VPS API, or Litestream replicating SQLite to R2 for edge reads.

**Reconciliation layer:** Provider billing APIs remain available for periodic comparison. A weekly script could compare `SUM(estimated_cost_usd)` against actual provider costs, flag drift > 10%, and adjust the pricing table. This is insurance, not infrastructure.

**Cross-tool integration:** Telemetry and Dispatch currently operate independently with separate SQLite databases. A future integration point would allow telemetry data to inform dispatch decisions â€” for example, automatically creating a high-priority task when a budget alert fires, or pausing low-priority agent tasks when spend exceeds a threshold.

**Plugin system:** The current architecture is intentionally simple. As the ecosystem grows, a lightweight plugin interface could allow community-built extensions (new providers, custom alert handlers, alternative storage backends) without bloating the core tools.

**Multi-host support:** The current model assumes a single host. For users running agents across multiple machines, a future version could aggregate data from multiple hosts into a central Telemetry instance.

---

_This document is a living reference. As the architecture evolves, so will this doc. If something is unclear or outdated, please [open an issue](https://github.com/max-geller/ground-control/issues)._
